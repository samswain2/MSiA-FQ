---
title: "Lab Assignment 01"
author: "Sam Swain"
date: "2022-10-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1

```{r}
df_1 = read.table("webtraffic.txt", header = TRUE)
```

### 1(A)

```{r}
df_1 = read.table("webtraffic.txt", header = TRUE)
# Create count matrix
df_1 <- colSums(df_1)
Traffic <- matrix(data = 0, nrow = 9, ncol = 9)
Traffic[9, 1] <- 1000
k = 1
for (i in 1:8) {
  for (j in 1:9) {
    Traffic[i, j] <- df_1[k]
    k = k + 1
  }
}

# Create probability matrix
Traffic_probability <- t(apply(Traffic ,1 , function(x) x/sum(x)))
Traffic
```

### 1(B)

```{r}
set.seed(6)
library(markovchain)

states <- c("1", "2", "3", "4", "5", "6", "7", "8", "9")

mc <- new("markovchain", states=states, transitionMatrix=Traffic_probability)

dimnames(Traffic_probability) <- list(states, states)
mc@transitionMatrix <- Traffic_probability

par(mar=c(0.1 ,0.1 , 0.1, 0.1))

plot(mc, edge.arrow.size=0.5, 
     vertex.size = 25, 
     edge.label.cex = 0.0001)
```

### 1(C)

```{r}
Traffic_probability
```

### 1(D)

The probability of a visitor being on Page 5 after 5 clicks is `r Traffic_probability[5, 5]`

### 1(E)

```{r}
Traffic_probability[9, 1] = 1; Traffic_probability[9, 9] = 0
Q=t(Traffic_probability) - diag(9)
Q[9,] = rep(1, 9)
rhs = c(rep(0, 8), 1)
Pi = solve(Q,rhs)
print(Pi)
```

### 1(F)

```{r}
B=Traffic_probability[1:8,1:8]
Q=diag(8)-B
rhs=c(0.1, 2, 3, 5, 5, 3, 3, 2)
m=solve(Q,rhs)
```

The average time a visitor spends on the website until he/she first leaves is `r m[1]` minutes.

# Question 2

### 2(A)

$$
n \ge \frac{var[p(x)]}{(tolerance)^2\delta} = \frac{\frac{1}{\lambda^2}}{(10^{-3})^2*0.01}
\ \therefore \ 
n \ge \frac{10^8}{\lambda^2}
$$

### 2(B)

```{r}
lambdas = c(1, 2, 4)
results = c()
results_real = c()

for (i in lambdas){
  
  n = 10^8/i^2
  x = runif(n, 0, 1)
  y = -log(x)/i
  g = sin(y)/i
  
  results = append(results, sum(g)/n)
  results_real = append(results_real, (1 / (1+i^2)))
}
```

#### Lambda = 1

Using MCMC, we get a value of `r results[1]`. This is different from the real result, `r results_real[1]` by `r abs(results[1]-results_real[1])`. Therefore it is within the tolerance.

#### Lambda = 2

Using MCMC, we get a value of `r results[2]`. This is different from the real result, `r results_real[2]` by `r abs(results[2]-results_real[2])`. Therefore it is within the tolerance.

#### Lambda = 4

Using MCMC, we get a value of `r results[3]`. This is different from the real result, `r results_real[3]` by `r abs(results[3]-results_real[3])`. Therefore it is within the tolerance.

# Question 3

### 3(A)

We can't use Metropolis Sampling because a gamma distribution is not symmetrical. Since gamma distributions aren't join distributions, we can't use Gibbs Sampling either. Therefore, we are left with Metropolis-Hastings Algorithm.

### 3(B)

```{r}
x = 1
n = 205000
storage = rep(0, n)

for (i in 1:n) {
  
  x_prime = rchisq(1, x)
  
  r_top = dchisq(x, x_prime) * dgamma(x = x_prime, shape = 2, scale = 2)
  r_bottom = dchisq(x, x) * dgamma(x = x, shape = 2, scale = 2)
    
  a = r_top/r_bottom
  
  u = runif(1, min = 0, max = 1)
  
  if (u <= a) {
    x = x_prime
  }
  
  storage[i] = x

}
```

```{r}
remove_burnin_storage = storage[5001:n]
storage_sampled = remove_burnin_storage[seq(1, n, 2000)]
storage_sampled = storage_sampled[!is.na(storage_sampled)]
```

### 3(C)

As we can see from the scatter plot below, the data seems to be random. Looking further into a time series plot, we can see there is no apparent correlation between concurrent observations.

```{r}
plot(storage_sampled)
```

```{r}
plot(ts(storage_sampled))
```